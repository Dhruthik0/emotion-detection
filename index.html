<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Webcam Emotion Detection</title>
    <style>
      body { font-family: Arial, sans-serif; display:flex; gap:20px; padding:20px; }
      #video, #canvas { border: 1px solid #ddd; }
      #controls { max-width: 360px; }
      .label { font-weight: 600; margin-top:10px; }
      #emotionBox { font-size: 20px; margin-top: 8px; }
      pre { background:#f7f7f7; padding:8px; border-radius:4px; overflow:auto; max-height:240px;}
    </style>
  </head>
  <body>
    <div>
      <video id="video" autoplay playsinline width="480" height="360"></video>
      <canvas id="canvas" width="480" height="360" style="display:none"></canvas>
    </div>

    <div id="controls">
      <div class="label">Detected Emotion</div>
      <div id="emotionBox">—</div>

      <div class="label">Confidence / All Emotions</div>
      <pre id="emotionsPre">{}</pre>

      <div style="margin-top:12px;">
        <button id="startBtn">Start</button>
        <button id="stopBtn">Stop</button>
      </div>

      <div style="margin-top:12px;">
        <label for="intervalMs">Send frame every (ms)</label><br/>
        <input id="intervalMs" type="number" value="800" min="100" />
      </div>

      <p style="margin-top:12px;color:#666">Note: frames are sent to the server for inference.</p>
    </div>

    <script>
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const emotionBox = document.getElementById('emotionBox');
      const emotionsPre = document.getElementById('emotionsPre');
      const startBtn = document.getElementById('startBtn');
      const stopBtn = document.getElementById('stopBtn');
      const intervalInput = document.getElementById('intervalMs');

      let stream = null;
      let intervalId = null;

      async function startCamera() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
          video.srcObject = stream;
        } catch (err) {
          alert('Could not access camera: ' + err);
        }
      }

      async function stopCamera() {
        if (stream) {
          stream.getTracks().forEach(t => t.stop());
          stream = null;
          video.srcObject = null;
        }
      }

      async function sendFrame() {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        canvas.toBlob(async (blob) => {
          if (!blob) return;
          const fd = new FormData();
          fd.append('file', blob, 'frame.jpg');

          try {
            const resp = await fetch('/predict', {
              method: 'POST',
              body: fd
            });
            if (!resp.ok) {
              const txt = await resp.text();
              console.error('Server error', resp.status, txt);
              return;
            }
            const data = await resp.json();
            emotionBox.innerText = data.dominant_emotion || '—';
            emotionsPre.innerText = JSON.stringify(data.emotions || {}, null, 2);

            if (data.region) {
              const { x, y, w, h } = data.region;
              ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
              ctx.strokeStyle = 'lime';
              ctx.lineWidth = 2;
              ctx.strokeRect(x, y, w, h);
            }
          } catch (err) {
            console.error('Network / parse error', err);
          }
        }, 'image/jpeg', 0.8);
      }

      startBtn.onclick = () => {
        startCamera();
        const ms = parseInt(intervalInput.value) || 800;
        if (intervalId) clearInterval(intervalId);
        intervalId = setInterval(sendFrame, ms);
      };

      stopBtn.onclick = () => {
        if (intervalId) clearInterval(intervalId);
        intervalId = null;
        stopCamera();
        emotionBox.innerText = '—';
        emotionsPre.innerText = '{}';
      };
    </script>
  </body>
</html>
